{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Required Environment:  \n",
    "\n",
    "Python: 3.9.18  \n",
    "Packages:  \n",
    "  > numpy, 1.19.5  \n",
    "  > sklearn, 1.3.0  \n",
    "  > matplotlib, 3.7.2  \n",
    "  > pickle, 4.0  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "health #original spectra of heathy subject <ndarray with n rows, m wavenumbers>\n",
    "hcc #original spectra of HCC subject <ndarray with n rows, m wavenumbers>\n",
    "\n",
    "train_raw_nc, test_raw_nc = train_test_split(health, \n",
    "                                               test_size=0.3, random_state=1)\n",
    "train_raw_macro, test_raw_macro = train_test_split(hcc,\n",
    "                                                 test_size=0.3, random_state=1)\n",
    "\n",
    "# A custom function to average spectras\n",
    "def bootStrapMean(inputData, nSampleForMean: int, outputSize, normalize=True):\n",
    "\n",
    "    # nSampleForMean: Determine how many samples were used to be averaged\n",
    "    # outputSize: Expected size of datasets after boot strapping\n",
    "\n",
    "    from sklearn.preprocessing import  MinMaxScaler\n",
    "\n",
    "    outputData = np.empty((outputSize, inputData.shape[1]))\n",
    "    row_order = np.arange(inputData.shape[0])\n",
    "    for i in outputSize:\n",
    "        np.random.shuffle(row_order)\n",
    "        idx = row_order[0:nSampleForMean]\n",
    "        outputData[i,:] = np.average(inputData[idx,:], axis=0)\n",
    "        if normalize is True:\n",
    "            scaler = MinMaxScaler()\n",
    "            outputData[i,:] = scaler.fit_transform(outputData[i,:].reshape(-1,1)).reshape(1,-1)\n",
    "\n",
    "    return outputData\n",
    "\n",
    "x_train = np.concatenate((bootStrapMean(train_raw_nc, 10, 10000), \n",
    "                          bootStrapMean(train_raw_macro, 10, 10000)),\n",
    "                          axis=0)\n",
    "x_test = np.concatenate((bootStrapMean(test_raw_nc, 10, 5000), \n",
    "                         bootStrapMean(test_raw_macro, 10, 5000)),\n",
    "                         axis=0)\n",
    "y_train = np.concatenate([np.repeat(0, 10000), np.repeat(1, 10000)])\n",
    "y_test = np.concatenate([np.repeat(0, 5000), np.repeat(1, 5000)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare 11 Candidate Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "names = [\"K-nearest Neighbors Classifier(K=5)\", \"Linear SVM\", \"SVM with RBF kernel\",\n",
    "         \"Decision Tree\", \"Random Forest\", \"AdaBoost Classifier\",\n",
    "         \"Naive Bayes Classifier\", \"LASSO Logistic\", \"Quadratic Discriminant Analysis\", \n",
    "         \"Gaussian Process Classifier\", \"Multi-layer Perceptron Classifier\"]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(5),\n",
    "    SVC(kernel=\"linear\", random_state=1),\n",
    "    SVC(kernel=\"rbf\", gamma='auto',  random_state=1),\n",
    "    DecisionTreeClassifier(random_state=1),\n",
    "    RandomForestClassifier(random_state=1),\n",
    "    AdaBoostClassifier(random_state=1),\n",
    "    GaussianNB(),\n",
    "    Lasso(random_state=1),\n",
    "    QuadraticDiscriminantAnalysis(),\n",
    "    GaussianProcessClassifier(random_state=1),\n",
    "    MLPClassifier(hidden_layer_sizes=5, activation='relu', learning_rate='adaptive', random_state=1)\n",
    "    ]\n",
    "\n",
    "x_t, x_v, y_t, y_v = train_test_split(x_train, y_train, test_size=0.3, random_state=1)\n",
    "\n",
    "#Excute\n",
    "clf_fitted = {}\n",
    "acc_v = []\n",
    "auc_v = []\n",
    "\n",
    "for name, clf in zip(names, classifiers):\n",
    "    print(name)\n",
    "    clf.fit(x_t, y_t)\n",
    "    clf_fitted[name] = clf\n",
    "\n",
    "    # Avoid prediction in prob, unified them into classes\n",
    "    y_t_pred = clf.predict(x_t)\n",
    "    y_t_pred = np.where(y_t_pred>=0.5,1,0)\n",
    "    y_v_pred = clf.predict(x_v)\n",
    "    y_v_pred = np.where(y_v_pred>=0.5,1,0)\n",
    "\n",
    "    acc_v.append(accuracy_score(y_v, y_v_pred))\n",
    "\n",
    "    auc_v.append(roc_auc_score(y_v, y_v_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tune hyperparameters of RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_estimators\n",
    "scores = []\n",
    "score_errors = []\n",
    "for i in range(1,30,3):\n",
    "    rfc = RandomForestClassifier(n_estimators=i, \n",
    "                                n_jobs=-1, \n",
    "                                oob_score=True,\n",
    "                                random_state=4)\n",
    "    cv = cross_val_score(rfc, x_train, y_train, scoring=\"roc_auc\",cv=10, n_jobs=-1)\n",
    "    score = cv.mean() \n",
    "    error = cv.std()\n",
    "    scores.append(score)\n",
    "    score_errors.append(error)\n",
    "\n",
    "# max_depth\n",
    "scores = []\n",
    "score_errors = []\n",
    "for i in range(1,30,3):\n",
    "    rfc = RandomForestClassifier(n_estimators=16,\n",
    "                                max_depth=i, \n",
    "                                n_jobs=-1, \n",
    "                                oob_score=True,\n",
    "                                random_state=4)\n",
    "    cv = cross_val_score(rfc, x_train, y_train, scoring=\"roc_auc\",cv=10, n_jobs=-1)\n",
    "    score = cv.mean() \n",
    "    error = cv.std()\n",
    "    scores.append(score)\n",
    "    score_errors.append(error)\n",
    "\n",
    "# max_features\n",
    "scores = []\n",
    "score_errors = []\n",
    "for i in range(1,30,3):\n",
    "    rfc = RandomForestClassifier(n_estimators=16,\n",
    "                                max_depth=10, \n",
    "                                max_features=i,\n",
    "                                n_jobs=-1, \n",
    "                                random_state=4)\n",
    "    cv = cross_val_score(rfc, x_train, y_train, scoring=\"roc_auc\",cv=10, n_jobs=-1)\n",
    "    score = cv.mean() \n",
    "    error = cv.std()\n",
    "    scores.append(score)\n",
    "    score_errors.append(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the final RF Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=16, \n",
    "                             max_depth=10,\n",
    "                             max_features=10,\n",
    "                             random_state=2)\n",
    "\n",
    "rfc.fit(x_train, y_train)\n",
    "y_train_pred = rfc.predict(x_train)\n",
    "y_test_pred = rfc.predict(x_test)\n",
    "\n",
    "trainscore = roc_auc_score(y_train, y_train_pred)\n",
    "testscore = roc_auc_score(y_test, y_test_pred)\n",
    "\n",
    "print('trainScore:{}'.format(trainscore))\n",
    "print('testScore:{}'.format(testscore))\n",
    "\n",
    "finalmodel = rfc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw ROC plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, precision_recall_fscore_support\n",
    "\n",
    "y_train_predp = rfc.predict_proba(x_train)[:,1]\n",
    "y_test_predp = rfc.predict_proba(x_test)[:,1]\n",
    "\n",
    "print(\"Train Set Metric:\")\n",
    "print(classification_report(y_train, y_train_pred))\n",
    "print(precision_recall_fscore_support(y_train, y_train_pred, pos_label=1))\n",
    "print(\"Test Set Metric:\")\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "print(precision_recall_fscore_support(y_test, y_test_pred, pos_label=1))\n",
    "\n",
    "fpr, tpr, thresh = roc_curve(y_train, y_train_predp,\n",
    "                            pos_label=1)\n",
    "\n",
    "fpr2, tpr2, thresh2 = roc_curve(y_test, y_test_predp,\n",
    "                                pos_label=1) \n",
    "\n",
    "plt.figure(figsize=(3.5,3.5))\n",
    "plt.rc('font', family='Arial', size=8)\n",
    "\n",
    "plt.plot(fpr2,tpr2,'--',color='darkgray', lw=2,\n",
    "         label=\"ROC test  (AUC = %0.3f)\" % roc_auc_score(y_test, y_test_pred))\n",
    "plt.plot(fpr,tpr,'-',color='gray', lw=2,\n",
    "         label=\"ROC train (AUC = %0.3f)\" % roc_auc_score(y_train, y_train_pred))\n",
    "plt.plot([0, 1], [0, 1], color=\"0.6\", lw=1, linestyle=\"--\")\n",
    "\n",
    "plt.xlim([-0.02, 1.02])\n",
    "plt.ylim([-0.02, 1.02])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Receiver Operating Characteristic\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "#plt.savefig(\"model_roc.pdf\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('font', family='Arial', size=8)\n",
    "\n",
    "fig1, ax = plt.subplots(1,2, figsize=(6,2), tight_layout=True)\n",
    "ax[0].set(title = \"Train (n=20000)\")\n",
    "ax[0] = ConfusionMatrixDisplay.from_predictions(y_train, y_train_pred, ax=ax[0], cmap=\"Greys\")\n",
    "ax[1].set(title=\"Test (n=10000)\")\n",
    "ax[1] =ConfusionMatrixDisplay.from_predictions(y_test, y_test_pred, ax=ax[1], cmap=\"Greys\")\n",
    "#fig1.savefig(r\".\\model_confusionMatrix.svg\", dpi=600, transparent=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autoML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
